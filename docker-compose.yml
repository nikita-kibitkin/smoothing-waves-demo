services:
  zookeeper:
    image: bitnami/zookeeper:3.9
    ports: ["2181:2181"]
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes

  kafka:
    image: bitnami/kafka:3.7
    ports:
      - "9092:9092"
      - "29092:29092"
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_CFG_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:29092
      KAFKA_CFG_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_CREATE_TOPICS: "high-topic:1:1,bulk-topic:1:1"

  pg:
    image: postgres:16
    ports: [ "5433:5432" ]
    environment:
      - POSTGRES_USERNAME=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DATABASE=postgres

      - POSTGRES_REPLICATION_MODE=master
      - POSTGRES_REPLICATION_USER=postgres
      - POSTGRES_REPLICATION_PASSWORD=postgres

      - POSTGRES_NUM_SYNCHRONOUS_REPLICAS=1
      - POSTGRES_SYNCHRONOUS_COMMIT=remote_apply

      - POSTGRES_WAL_LEVEL=replica
      - POSTGRES_MAX_WAL_SENDERS=10
      - POSTGRES_MAX_REPLICATION_SLOTS=10
      - POSTGRES_SHARED_BUFFERS=256MB
      - POSTGRES_LOG_CONNECTIONS=true
      - POSTGRES_LOG_DISCONNECTIONS=true
    command:
      - "postgres"
      - "-c"
      - "listen_addresses=*"
      - "-c"
      - "wal_level=replica"
      - "-c"
      - "max_wal_senders=10"
      - "-c"
      - "max_replication_slots=10"
      - "-c"
      - "synchronous_commit=remote_apply"
      - "-c"
      - "synchronous_standby_names=standby1"
      - "-c"
      - "hba_file=/etc/postgresql/pg_hba.conf"
    volumes:
      - pg_data:/bitnami/postgresql`
      - ./pg_hba.conf:/etc/postgresql/pg_hba.conf:ro

  toxiproxy:
    image: ghcr.io/shopify/toxiproxy:2.9.0
    container_name: toxiproxy
    ports:
      - "8666:8666"   # admin API
      - "15432:15432" # listener для репликации
    command: [ "-host=0.0.0.0","-port=8666" ]
    healthcheck:
      test: [ "CMD","/toxiproxy-cli","-h","127.0.0.1","-p","8666","list" ]
      interval: 5s
      timeout: 3s
      retries: 20

  pg_standby:
    image: bitnami/postgresql:16
    container_name: pg_standby
    depends_on: [pg]
    # NET_ADMIN нужен для tc netem
    cap_add: ["NET_ADMIN"]
    environment:
      - POSTGRES_REPLICATION_MODE=slave
      - POSTGRES_REPLICATION_USER=postgres
      - POSTGRES_REPLICATION_PASSWORD=postgres
      - POSTGRES_MASTER_HOST=pg
      - POSTGRES_MASTER_PORT_NUMBER=5432

      # Этими учётками standby тоже создаёт такую же БД/пользователя
      - POSTGRES_USERNAME=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DATABASE=postgres

      # Имя приложения реплики — попадёт в pg_stat_replication.application_name
      - POSTGRES_CLUSTER_APP_NAME=standby1

      - POSTGRES_SYNCHRONOUS_COMMIT=off
    # Вставим искусственную сетевую задержку 15 мс (≈30 мс RTT)
    command: >
      bash -lc '
        export PATH=/opt/bitnami/postgresql/bin:$PATH
        until pg_isready -h pg -p 5432 -U postgres; do sleep 1; done;
        tc qdisc add dev eth0 root netem delay 15ms || true;
        exec /opt/bitnami/scripts/postgresql/run.sh
      '
    volumes:
      - pg_standby_data:/var/lib/postgresql/data
      - ./pg_hba.conf:/etc/postgresql/pg_hba.conf:ro

  app:
    build: .
    ports: ["8080:8080"]
    depends_on:
      - kafka
      - pg
    environment:
      # fix heap to the memory limit with a small reserve
      - JAVA_TOOL_OPTIONS=-Xms1g -Xmx1g -XX:+AlwaysPreTouch
      - DURATION_MINUTES
      - EXPERIMENT_ID
      - BACKPRESSURE_ENABLED
      - BACKPRESSURE_CREDITS
      - DB_ENABLED
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2g
    cpuset: "0-1"

  prometheus:
    image: prom/prometheus:v2.53.0
    ports: ["9090:9090"]
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml

  grafana:
    image: grafana/grafana:10.4.1
    ports: ["3000:3000"]
    volumes:
      - ./grafana/provisioning:/etc/grafana/provisioning
      - ./grafana/dashboards:/var/lib/grafana/dashboards

volumes:
   pg_data:
   pg_standby_data: